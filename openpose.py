# -*- coding: utf-8 -*-
"""Untitled38.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jkZHPpxPRyr1773yhYJrMZ_pGRTHkhKl
"""

!pip uninstall -y mediapipe -q

!pip install mediapipe==0.10.32 -q

!pip install mediapipe==0.10.32 opencv-python numpy pandas scikit-learn tqdm -q

import mediapipe as mp
print(mp.__version__)
print(hasattr(mp, "solutions"))

!pip install ultralytics opencv-python numpy pandas scikit-learn tqdm -q

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm

from ultralytics import YOLO

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
from sklearn.neural_network import MLPClassifier

DATASET_DIR = "sports_videos"   # <-- must contain class folders
OUTPUT_CSV = "pose_dataset.csv"

SAMPLE_RATE = 5
POSE_MODEL = "yolov8n-pose.pt"

pose_model = YOLO(POSE_MODEL)

def extract_yolo_pose_keypoints(frame):
    results = pose_model(frame, verbose=False)

    if len(results) == 0:
        return None

    r = results[0]

    if r.keypoints is None:
        return None

    kpts_xy = r.keypoints.xy

    if kpts_xy is None or len(kpts_xy) == 0:
        return None

    return kpts_xy

from ultralytics import YOLO
import numpy as np

pose_model = YOLO("yolov8n-pose.pt")

def extract_yolo_pose_keypoints(frame):
    results = pose_model(frame, verbose=False)

    if len(results) == 0:
        return None

    r = results[0]

    if r.keypoints is None:
        return None

    kpts_xy = r.keypoints.xy

    if kpts_xy is None or len(kpts_xy) == 0:
        return None

    person_xy = kpts_xy[0].cpu().numpy()  # (17,2)

    return person_xy.flatten()  # (34,)

import cv2

img = cv2.imread("test.jpg")   # give any image
k = extract_yolo_pose_keypoints(img)

print("Keypoints shape:", None if k is None else k.shape)

def process_video(video_path, label):
    cap = cv2.VideoCapture(video_path)
    rows = []
    frame_id = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_id += 1

        if frame_id % SAMPLE_RATE != 0:
            continue

        keypoints = extract_yolo_pose_keypoints(frame)

        if keypoints is not None:
            row = keypoints.tolist()
            row.append(label)
            rows.append(row)

    cap.release()
    return rows

import os
print("Current path:", os.getcwd())
print("Files here:", os.listdir())

import os
print(os.listdir("/content"))

from google.colab import files
uploaded = files.upload()

import os, shutil

os.makedirs("/content/cricket_videos", exist_ok=True)

for file in uploaded.keys():
    shutil.move(file, "/content/cricket_videos/" + file)

print("âœ… Videos moved to /content/cricket_videos")

import os
print(os.listdir("/content/cricket_videos"))

import os
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
from tqdm import tqdm

VIDEO_DIR = "/content/cricket_videos"
OUTPUT_CSV = "cricket_pose_keypoints.csv"
SAMPLE_RATE = 5

pose_model = YOLO("yolov8n-pose.pt")

def extract_keypoints(frame):
    results = pose_model(frame, verbose=False)
    if len(results) == 0:
        return None

    r = results[0]

    if r.keypoints is None:
        return None

    kpts_xy = r.keypoints.xy
    if kpts_xy is None or len(kpts_xy) == 0:
        return None

    person_xy = kpts_xy[0].cpu().numpy()   # (17,2)
    return person_xy.flatten()             # (34,)


all_rows = []
total_frames = 0
pose_detected = 0

video_files = [f for f in os.listdir(VIDEO_DIR) if f.endswith((".mp4", ".avi", ".mov", ".mkv"))]

print("âœ… Total videos found:", len(video_files))

for vid in tqdm(video_files):
    video_path = os.path.join(VIDEO_DIR, vid)
    cap = cv2.VideoCapture(video_path)

    frame_id = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_id += 1

        if frame_id % SAMPLE_RATE != 0:
            continue

        total_frames += 1

        keypoints = extract_keypoints(frame)

        if keypoints is not None:
            pose_detected += 1
            row = keypoints.tolist()
            row.append(vid)
            all_rows.append(row)

    cap.release()


if len(all_rows) == 0:
    print("âŒ No pose detected in any frames!")
    raise SystemExit


columns = [f"f{i}" for i in range(len(all_rows[0]) - 1)] + ["video_name"]
df = pd.DataFrame(all_rows, columns=columns)
df.to_csv(OUTPUT_CSV, index=False)

pose_detection_rate = (pose_detected / total_frames) * 100 if total_frames > 0 else 0

print("\n==============================")
print("ðŸ“Œ FINAL RESULTS")
print("==============================")
print("Total Frames Checked:", total_frames)
print("Pose Detected Frames:", pose_detected)
print("Pose Detection Rate (Accuracy %):", pose_detection_rate)
print("Saved CSV File:", OUTPUT_CSV)

import os
import cv2
from ultralytics import YOLO

# -----------------------------
# SETTINGS
# -----------------------------
VIDEO_PATH = "/content/cricket_videos"   # folder
OUTPUT_VIDEO = "pose_output.mp4"
OUTPUT_FRAMES_DIR = "pose_frames"

os.makedirs(OUTPUT_FRAMES_DIR, exist_ok=True)

pose_model = YOLO("yolov8n-pose.pt")

# pick first video automatically
video_files = [f for f in os.listdir(VIDEO_PATH) if f.endswith((".mp4", ".avi", ".mov", ".mkv"))]

if len(video_files) == 0:
    print("âŒ No videos found!")
    raise SystemExit

input_video = os.path.join(VIDEO_PATH, video_files[0])
print("âœ… Using video:", input_video)

cap = cv2.VideoCapture(input_video)

width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))

frame_count = 0
saved_frames = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_count += 1

    results = pose_model(frame, verbose=False)

    if len(results) > 0:
        annotated = results[0].plot()   # draws skeleton automatically
    else:
        annotated = frame

    out.write(annotated)

    # save 5 screenshot frames
    if frame_count % 50 == 0 and saved_frames < 5:
        frame_name = f"{OUTPUT_FRAMES_DIR}/frame_{frame_count}.jpg"
        cv2.imwrite(frame_name, annotated)
        saved_frames += 1

cap.release()
out.release()

print("âœ… Output video saved as:", OUTPUT_VIDEO)
print("âœ… Screenshot frames saved inside folder:", OUTPUT_FRAMES_DIR)